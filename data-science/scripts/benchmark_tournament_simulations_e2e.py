from __future__ import annotations

import argparse
import os
import time
from typing import Iterable, Tuple

import pandas as pd
import psycopg2
import psycopg2.extras

from moneyball.models.simulated_tournaments_db import (
    simulate_tournaments_from_predictions,
)


def _connect() -> psycopg2.extensions.connection:
    database_url = os.getenv("DATABASE_URL", "").strip()
    if database_url:
        return psycopg2.connect(database_url)

    return psycopg2.connect(
        host=os.getenv("DB_HOST", "localhost"),
        port=int(os.getenv("DB_PORT", "5432")),
        dbname=os.getenv("DB_NAME", "calcutta"),
        user=os.getenv("DB_USER", "calcutta"),
        password=os.getenv("DB_PASSWORD", "calcutta"),
    )


def _resolve_tournament_ids(
    conn: psycopg2.extensions.connection,
    season: int,
) -> Tuple[str, str]:
    with conn.cursor() as cur:
        cur.execute(
            """
            SELECT t.id, t.core_tournament_id
            FROM lab_bronze.tournaments t
            WHERE t.season = %s
              AND t.deleted_at IS NULL
            ORDER BY t.created_at DESC
            LIMIT 1
            """,
            (season,),
        )
        row = cur.fetchone()
        if not row:
            raise ValueError(f"No lab tournament found for season={season}")
        lab_tournament_id = str(row[0])
        core_tournament_id = str(row[1] or "")
        if not core_tournament_id:
            raise ValueError(
                (
                    "lab_bronze.tournaments.core_tournament_id is NULL "
                    f"for season={season}"
                )
            )
        return lab_tournament_id, core_tournament_id


def _load_teams(
    conn: psycopg2.extensions.connection,
    lab_tournament_id: str,
) -> pd.DataFrame:
    return pd.read_sql_query(
        """
        SELECT id, school_name, seed, region
        FROM lab_bronze.teams
        WHERE tournament_id = %s
          AND deleted_at IS NULL
        ORDER BY seed ASC
        """,
        conn,
        params=(lab_tournament_id,),
    )


def _load_predictions(
    conn: psycopg2.extensions.connection,
    lab_tournament_id: str,
) -> pd.DataFrame:
    df = pd.read_sql_query(
        """
        SELECT team1_id, team2_id, p_team1_wins
        FROM lab_silver.predicted_game_outcomes
        WHERE tournament_id = %s
          AND deleted_at IS NULL
        """,
        conn,
        params=(lab_tournament_id,),
    )
    # Match DB-first simulator expected column name
    df = df.rename(columns={"p_team1_wins": "p_team1_wins_given_matchup"})
    return df


def _create_tournament_state_snapshot(
    conn: psycopg2.extensions.connection,
    core_tournament_id: str,
) -> str:
    with conn.cursor() as cur:
        cur.execute(
            """
            INSERT INTO analytics.tournament_state_snapshots (
                tournament_id,
                source,
                description
            )
            VALUES (
                %s,
                'python_benchmark',
                'Autogenerated snapshot for end-to-end simulation benchmark'
            )
            RETURNING id
            """,
            (core_tournament_id,),
        )
        snapshot_id = str(cur.fetchone()[0])

        cur.execute(
            """
            INSERT INTO analytics.tournament_state_snapshot_teams (
                tournament_state_snapshot_id,
                team_id,
                wins,
                byes,
                eliminated
            )
            SELECT
                %s,
                ct.id,
                ct.wins,
                ct.byes,
                ct.eliminated
            FROM core.teams ct
            WHERE ct.tournament_id = %s
              AND ct.deleted_at IS NULL
            ON CONFLICT (tournament_state_snapshot_id, team_id) DO NOTHING
            """,
            (snapshot_id, core_tournament_id),
        )

    conn.commit()
    return snapshot_id


def _create_simulation_batch(
    conn: psycopg2.extensions.connection,
    core_tournament_id: str,
    snapshot_id: str,
    n_sims: int,
    seed: int,
    probability_source_key: str,
) -> str:
    with conn.cursor() as cur:
        cur.execute(
            """
            INSERT INTO analytics.tournament_simulation_batches (
                tournament_id,
                tournament_state_snapshot_id,
                n_sims,
                seed,
                probability_source_key
            )
            VALUES (%s, %s, %s, %s, %s)
            RETURNING id
            """,
            (
                core_tournament_id,
                snapshot_id,
                int(n_sims),
                int(seed),
                probability_source_key,
            ),
        )
        batch_id = str(cur.fetchone()[0])

    conn.commit()
    return batch_id


def _rows_for_insert(
    *,
    batch_id: str,
    lab_tournament_id: str,
    sim_id_offset: int,
    chunk_df: pd.DataFrame,
) -> Iterable[Tuple[str, str, int, str, int, int, bool]]:
    # eliminated: only the champion is not eliminated.
    # Compute per-sim champion progress and compare.
    df = chunk_df.copy()
    df["sim_id"] = df["sim_id"].astype(int) + int(sim_id_offset)
    df["wins"] = df["wins"].astype(int)
    df["byes"] = df["byes"].astype(int)

    df["progress"] = df["wins"] + df["byes"]
    champ_progress = df.groupby("sim_id")["progress"].transform("max")
    df["eliminated"] = df["progress"] < champ_progress

    for row in df.itertuples(index=False):
        yield (
            batch_id,
            lab_tournament_id,
            int(row.sim_id),
            str(row.team_id),
            int(row.wins),
            int(row.byes),
            bool(row.eliminated),
        )


def _insert_simulated_tournaments(
    conn: psycopg2.extensions.connection,
    *,
    batch_id: str,
    lab_tournament_id: str,
    sim_id_offset: int,
    chunk_df: pd.DataFrame,
) -> int:
    rows = list(
        _rows_for_insert(
            batch_id=batch_id,
            lab_tournament_id=lab_tournament_id,
            sim_id_offset=sim_id_offset,
            chunk_df=chunk_df,
        )
    )
    with conn.cursor() as cur:
        psycopg2.extras.execute_values(
            cur,
            """
            INSERT INTO analytics.simulated_tournaments
                (
                    tournament_simulation_batch_id,
                    tournament_id,
                    sim_id,
                    team_id,
                    wins,
                    byes,
                    eliminated
                )
            VALUES %s
            """,
            rows,
            page_size=10000,
        )
    conn.commit()
    return len(rows)


def main() -> None:
    p = argparse.ArgumentParser(
        description="End-to-end tournament simulation benchmark (Python)"
    )
    p.add_argument("--season", type=int, required=True)
    p.add_argument("--n-sims", type=int, default=100000)
    p.add_argument("--seed", type=int, default=42)
    p.add_argument("--chunk-size", type=int, default=1000)
    p.add_argument(
        "--probability-source-key",
        type=str,
        default="python_benchmark",
    )
    args = p.parse_args()

    if args.n_sims <= 0:
        raise ValueError("--n-sims must be positive")
    if args.chunk_size <= 0:
        raise ValueError("--chunk-size must be positive")

    t0 = time.time()
    conn = _connect()
    conn.autocommit = False

    try:
        t_load0 = time.time()
        lab_tournament_id, core_tournament_id = _resolve_tournament_ids(
            conn,
            args.season,
        )
        teams_df = _load_teams(conn, lab_tournament_id)
        predictions_df = _load_predictions(conn, lab_tournament_id)
        t_load1 = time.time()

        if len(teams_df) != 68:
            raise ValueError(
                f"Expected 68 teams, got {len(teams_df)}"
            )

        snapshot_id = _create_tournament_state_snapshot(conn, core_tournament_id)
        batch_id = _create_simulation_batch(
            conn,
            core_tournament_id,
            snapshot_id,
            n_sims=args.n_sims,
            seed=args.seed,
            probability_source_key=args.probability_source_key,
        )

        print(
            (
                f"Loaded season={args.season} "
                f"lab_tournament_id={lab_tournament_id} "
                f"core_tournament_id={core_tournament_id} "
                f"teams={len(teams_df)} "
                f"predictions={len(predictions_df)} "
                f"in {t_load1 - t_load0:.3f}s"
            )
        )
        print(
            f"Created snapshot_id={snapshot_id} batch_id={batch_id}"
        )

        t_sim0 = time.time()
        total_inserted = 0
        sim_offset = 0
        chunk_idx = 0

        while sim_offset < args.n_sims:
            chunk_idx += 1
            n = min(args.chunk_size, args.n_sims - sim_offset)

            # Seed policy matches Go.
            # Vary by chunk offset so the full run is reproducible.
            chunk_seed = int(args.seed) + int(sim_offset) * 1_000_003

            chunk_df = simulate_tournaments_from_predictions(
                predictions_df=predictions_df,
                teams_df=teams_df,
                n_sims=n,
                seed=chunk_seed,
                points_by_win_index={},
            )

            # normalize output columns
            chunk_df = chunk_df[
                ["team_id", "sim_id", "wins", "byes"]
            ].copy()

            t_write0 = time.time()
            inserted = _insert_simulated_tournaments(
                conn,
                batch_id=batch_id,
                lab_tournament_id=lab_tournament_id,
                sim_id_offset=sim_offset,
                chunk_df=chunk_df,
            )
            t_write1 = time.time()

            total_inserted += inserted
            sim_offset += n

            print(
                (
                    f"Chunk {chunk_idx} sims={n} "
                    f"sim_offset={sim_offset} "
                    f"inserted_rows={inserted} "
                    f"write={t_write1 - t_write0:.3f}s "
                    f"elapsed={time.time() - t_sim0:.3f}s"
                )
            )

        t_sim1 = time.time()
        t1 = time.time()

        print(
            f"DONE season={args.season} n_sims={args.n_sims} chunk_size={args.chunk_size} rows={total_inserted}"
        )
        print(
            (
                f"Timing: load={t_load1 - t_load0:.3f}s "
                f"simulate+write={t_sim1 - t_sim0:.3f}s "
                f"overall={t1 - t0:.3f}s"
            )
        )

    finally:
        conn.close()


if __name__ == "__main__":
    main()
